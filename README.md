# Titanic - Machine Learning from Disaster

## Project Overview
This project is an analysis and model training exercise based on the Kaggle dataset **"Titanic - Machine Learning from Disaster"**. The main objectives include data exploration, feature engineering, and training and evaluating machine learning models. The project is divided into two Jupyter notebooks:

1. **Titanic**: Includes data preprocessing steps and the implementation of the **Deep Forest** machine learning model.
2. **Titanic (with cabin)**: Extends the previous model by including cabin information analysis.

## Dataset Source
The dataset used in this project is sourced from [Kaggle](https://www.kaggle.com/competitions/titanic).

## References
This project references similar exercises and publicly available projects.

## How to Run the Project
1. Clone the repository containing these notebooks.
2. Install the required dependencies listed in the `requirements.txt` file (if provided):
   ```bash
   pip install -r requirements.txt
   ```
3. Open each notebook in Jupyter or a similar environment:
   ```bash
   jupyter notebook
   ```
4. Follow the steps in each notebook, starting with data analysis, then moving to model training.

## Notes
- This project is intended for educational purposes.

---

## Contact
For any questions or suggestions regarding this project, feel free to reach out.

